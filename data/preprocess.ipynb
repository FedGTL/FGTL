{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def create_random_split(graph, split : list):\n",
    "\n",
    "    assert(len(split) == 3)\n",
    "    \n",
    "    idx = np.arange(graph.num_nodes)\n",
    "    random.shuffle(idx)\n",
    "\n",
    "    train_size = int(graph.num_nodes * (split[0] / 10))\n",
    "    val_size = int(graph.num_nodes * (split[1] / 10))\n",
    "    test_size = int(graph.num_nodes * (split[2] / 10))\n",
    "\n",
    "    train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[idx[:train_size]] = True\n",
    "    val_mask[idx[train_size: train_size + val_size]] = True\n",
    "    test_mask[idx[train_size + val_size:]] = True\n",
    "\n",
    "    graph.train_mask = train_mask\n",
    "    graph.val_mask = val_mask\n",
    "    graph.test_mask = test_mask\n",
    "\n",
    "# create_random_split(graph, [1, 1, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subgraph sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx, degree, k_hop_subgraph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def _convert_to_nodeDegreeFeatures(graphs):\n",
    "    graph_infos = []\n",
    "    maxdegree = 0\n",
    "    for i, graph in enumerate(graphs):\n",
    "        g = to_networkx(graph, to_undirected=True)\n",
    "        gdegree = max(dict(g.degree).values())\n",
    "        if gdegree > maxdegree:\n",
    "            maxdegree = gdegree\n",
    "        graph_infos.append((graph, g.degree, graph.num_nodes))    # (graph, node_degrees, num_nodes)\n",
    "\n",
    "    new_graphs = []\n",
    "    for i, tpl in enumerate(graph_infos):\n",
    "        idx, x = tpl[0].edge_index[0], tpl[0].x\n",
    "        deg = degree(idx, tpl[2], dtype=torch.long)\n",
    "        deg = F.one_hot(deg, num_classes=maxdegree + 1).to(torch.float)\n",
    "\n",
    "        new_graph = tpl[0].clone()\n",
    "        new_graph.__setitem__('x', deg)\n",
    "        new_graphs.append(new_graph)\n",
    "\n",
    "    return new_graphs\n",
    "\n",
    "def to_egoNet(graph, ego, hop_number): \n",
    "    # get ego-networks for sampled nodes\n",
    "    sub_nodes, sub_edge_index, _, _ = k_hop_subgraph(ego, hop_number, graph.edge_index)\n",
    "    \n",
    "    def re_index(source):\n",
    "        mapping = dict(zip(sub_nodes.numpy(), range(sub_nodes.shape[0])))\n",
    "        return mapping[source]\n",
    "    \n",
    "    edge_index_u = [*map(re_index, sub_edge_index[0][:].numpy())]\n",
    "    edge_index_v = [*map(re_index, sub_edge_index[1][:].numpy())]\n",
    "\n",
    "    egonet = Data(edge_index=torch.tensor([edge_index_u, edge_index_v]), x=graph.x[sub_nodes], y=graph.y[sub_nodes])\n",
    "    return egonet\n",
    "\n",
    "def get_egonetworks(graph, ego_number, hop_number, sampling, dataset_split : bool = False):\n",
    "    ego_number = min(ego_number, graph.num_nodes)\n",
    "    \n",
    "    num_graphs = ego_number\n",
    "    num_features = graph.num_node_features\n",
    "    num_labels = len(graph.y.unique())\n",
    "\n",
    "    if sampling == 'random':\n",
    "        # egos = []\n",
    "        # batch_size = graph.num_nodes // ego_number\n",
    "        # for i in range(ego_number):\n",
    "        #     egos += random.sample(range(batch_size * i, batch_size * (i+1)), 1)\n",
    "        egos = random.sample(range(graph.num_nodes), ego_number)\n",
    "        print(\"random ego central nodes:{}\".format(egos))\n",
    "        egonetworks = [to_egoNet(graph, ego, hop_number) for ego in egos]\n",
    "\n",
    "    if sampling == 'byLabel':\n",
    "        egos_byLabel = {}\n",
    "        allLabels = graph.y.unique()\n",
    "        for label in allLabels:\n",
    "            idx_label = np.where(graph.y == label)[0]\n",
    "            egos_byLabel[label.item()] = random.sample(list(idx_label), ego_number)    # ego_number is per client in this case (should be smaller)\n",
    "\n",
    "        egonetworks = {k: [to_egoNet(graph, ego.item(), hop_number) for ego in v] for k, v in egos_byLabel.items()}\n",
    "        num_graphs = len(allLabels) * ego_number\n",
    "\n",
    "    if (sampling == 'random' and not egonetworks[0].__contains__('x')):\n",
    "        egonetworks = _convert_to_nodeDegreeFeatures(egonetworks)\n",
    "\n",
    "    if (sampling == 'byLabel' and not list(egonetworks.values())[0].__contains__('x')):\n",
    "        egonetworks = {k: _convert_to_nodeDegreeFeatures(v) for k, v in egonetworks.items()}\n",
    "\n",
    "    if dataset_split:\n",
    "        for subgraph in egonetworks:\n",
    "            create_random_split(subgraph, [1, 1, 8])\n",
    "\n",
    "    return egonetworks, num_graphs, num_features, num_labels\n",
    "\n",
    "\n",
    "def log_subgraphs(subgraphs):\n",
    "    for idx, subgraph in enumerate(subgraphs): \n",
    "        print(\"----------ego {}----------\".format(idx))\n",
    "        print(subgraph)\n",
    "        print(\"node label: \", subgraph.y.unique())\n",
    "        for label in subgraph.y.unique():\n",
    "            print(\"{} label node number: \".format(label), (subgraph.y == label).sum().item())\n",
    "\n",
    "\n",
    "# subgraphs, num_graphs, num_features, num_labels = get_egonetworks(graph.cpu(), ego_number=6, hop_number=10, sampling='random', dataset_split=False)\n",
    "# log_subgraphs(subgraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mat2Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def load_network(file:str, dataset_split: bool = False) -> Data:\n",
    "    net = sio.loadmat(file)\n",
    "    x, a, y = net['attrb'], net['network'].todense(), net['group']\n",
    "    \n",
    "    A = torch.tensor(np.where(a == 1), dtype = torch.long)\n",
    "    X = torch.tensor(x, dtype = torch.float)\n",
    "    Y = torch.tensor(np.argmax(y, axis = 1))\n",
    "\n",
    "    graph = Data(x=X, edge_index=A, y=Y)\n",
    "\n",
    "    if dataset_split:\n",
    "        create_random_split(graph, [1, 1, 8])\n",
    "\n",
    "    return graph\n",
    "\n",
    "# graph = load_network(file, dataset_split = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_egographs(data: list, outfile):\n",
    "    '''\n",
    "    data: [subgraphs, num_graphs, num_features, num_labels]\n",
    "    outfile: file to save\n",
    "    '''\n",
    "    pickle.dump(data, open(outfile, 'wb'))\n",
    "    print(f\"Wrote to {outfile}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyecharts\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "import numpy as np\n",
    "import torch_geometric\n",
    "\n",
    "from pyecharts.globals import CurrentConfig, NotebookType\n",
    "CurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_NOTEBOOK\n",
    "\n",
    "def visualize(g : torch_geometric.data.Data = None, gName : str = None):\n",
    "    repulsion_size = 800000\n",
    "\n",
    "    nodes = [opts.GraphNode(name=str(idx), category=label.item()) for idx, label in zip(range(g.num_nodes), g.y)]\n",
    "\n",
    "    links = [opts.GraphLink(source=s.item(), target=t.item()) for s, t in zip(g.edge_index[0], g.edge_index[1])]\n",
    "\n",
    "    categories = []\n",
    "    classes = np.unique(g.y)\n",
    "    for i in classes:\n",
    "        categories.append(opts.GraphCategory(name=str(i)))\n",
    "\n",
    "    c = (\n",
    "        Graph()\n",
    "        .add(\"\", nodes, links, categories, repulsion=repulsion_size)\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=gName))\n",
    "    )\n",
    "\n",
    "    c.load_javascript()\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset1 process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "acm_path = \"dataset1/acmv9.mat\"\n",
    "citation_path = \"dataset1/citationv1.mat\"\n",
    "dblp_path = \"dataset1/dblpv7.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from describe import describe\n",
    "\n",
    "acm = load_network(acm_path, True)\n",
    "print(\"acm:\")\n",
    "describe(acm, infos=['basic', 'label', 'degree'], deg_types = ['out'])\n",
    "\n",
    "citation = load_network(citation_path, True)\n",
    "print(\"citation:\")\n",
    "describe(citation, infos=['basic', 'label', 'degree'], deg_types = ['out'])\n",
    "\n",
    "dblp = load_network(dblp_path, True)\n",
    "print(\"dblp:\")\n",
    "describe(dblp, infos=['basic', 'label', 'degree'], deg_types = ['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = visualize(acm, \"acm\")\n",
    "# c.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = visualize(citation, \"citation\")\n",
    "# c.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = visualize(dblp, \"dblp\")\n",
    "# c.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ac2d.pkl\n",
    "acm_subgraphs, acm_num_graphs, num_features, num_labels = get_egonetworks(acm, ego_number=2, hop_number=10, sampling='random', dataset_split=True)\n",
    "log_subgraphs(acm_subgraphs)\n",
    "\n",
    "citation_subgraphs, citation_num_graphs, num_features, num_labels = get_egonetworks(citation, ego_number=2, hop_number=10, sampling='random', dataset_split=True)\n",
    "log_subgraphs(citation_subgraphs)\n",
    "\n",
    "subgraphs = acm_subgraphs + citation_subgraphs\n",
    "subgraphs.append(dblp)\n",
    "num_graphs = acm_num_graphs + citation_num_graphs + 1\n",
    "\n",
    "save_egographs([[acm, citation, dblp], 3, num_features, num_labels], outfile='dataset1/ac2d_3.pkl')\n",
    "save_egographs([subgraphs, num_graphs, num_features, num_labels], outfile=f'dataset1/ac2d_{num_graphs}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ad2c.pkl\n",
    "acm_subgraphs, acm_num_graphs, num_features, num_labels = get_egonetworks(acm, ego_number=2, hop_number=10, sampling='random', dataset_split=True)\n",
    "log_subgraphs(acm_subgraphs)\n",
    "\n",
    "dblp_subgraphs, dblp_num_graphs, num_features, num_labels = get_egonetworks(dblp, ego_number=2, hop_number=10, sampling='random', dataset_split=True)\n",
    "log_subgraphs(dblp_subgraphs)\n",
    "\n",
    "subgraphs = acm_subgraphs + dblp_subgraphs\n",
    "subgraphs.append(citation)\n",
    "num_graphs = acm_num_graphs + dblp_num_graphs + 1\n",
    "\n",
    "save_egographs([[acm, dblp, citation], 3, num_features, num_labels], outfile='dataset1/ad2c_3.pkl')\n",
    "save_egographs([subgraphs, num_graphs, num_features, num_labels], outfile=f'dataset1/ad2c_{num_graphs}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cd2a.pkl\n",
    "citation_subgraphs, citation_num_graphs, num_features, num_labels = get_egonetworks(citation, ego_number=2, hop_number=10, sampling='random', dataset_split=True)\n",
    "log_subgraphs(citation_subgraphs)\n",
    "\n",
    "dblp_subgraphs, dblp_num_graphs, num_features, num_labels = get_egonetworks(dblp, ego_number=2, hop_number=10, sampling='random', dataset_split=True)\n",
    "log_subgraphs(dblp_subgraphs)\n",
    "\n",
    "subgraphs = citation_subgraphs + dblp_subgraphs\n",
    "subgraphs.append(acm)\n",
    "num_graphs = citation_num_graphs + dblp_num_graphs + 1\n",
    "\n",
    "save_egographs([[citation, dblp, acm], 3, num_features, num_labels], outfile='dataset1/cd2a_3.pkl')\n",
    "save_egographs([subgraphs, num_graphs, num_features, num_labels], outfile=f'dataset1/cd2a_{num_graphs}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c3868a6a8dc88c2d53e9fd4eb413d463332bae2f8436ec3946685836fda535a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
